---
layout: default
---
<h1> ATKearney: Complete ETL, Data Warehousing & Cloud Analytic Solution for Online Patent Data </h1>

<h2><b>Tech Stack: Python, Scrapy, AWS Redshift, Postgres, Aginity Workbench, xPATH, AWS S3. </b> </h2>

<h3> <b> Project Affiliation: Capstone Project for ATKearney @Carnegie Mellon University, under Prof. TK Lim, Prof. Shyam Kekre, Prof. Sundar Kekre. </h3>

<h3> As part of my final semester capstone project at CMU, I was assigned to work for a client of ATKearney who wanted analyze certain patent behavior utilizing technology. They were also looking for recommendations based on certain criterion which I cannot disclose, but can provide an overview of the technical challenge that was posed and the solution that I came up with. </h3>

<h3> Imagine trying to analyze trends or coming up with an analysis, without having any data to do so. It was a tough job as I had to first source the relevant data as what we were looking for was a relatively new field in technology with no dataset available from the client side. The client wanted to understand what was going on in the field of patents for a particular technology and which of their competitors were doing what with respect to that technology. </h3>

<h3> I decided to scour the internet and find relevant and new data that can be used in the analysis for the same. I came across three really good data sources for patents which were: lens.org, USPTO and US PAIR. Two of these were government organizations that provided open source data about patents and their inventors. <h3>

<h3> I wanted to extract data, transform it and load it into a data warehouse such as Amazon's managed data warehouse Redshift and provide an analytical interface like SQL for the client to use so that post our engagement, they can still perform the analysis on their own. I wanted to host this on the cloud as I did not want to think about provisioning servers and infra redundancy as the data was going to be pretty big, possible over 200000 entries which were each quite detailed. Also, for such an analytic solution, I wanted to rely on a relational database system as I perfectly knew what the schema of the data was going to look like and it was highly unlikely that the schema was going to change anytime soon. Another reason for choosing a relational database was that the client was looking to perform transactional queries and not batch processing queries.</h3>

<h3> I came up with a solution diagram as shown below: </h3>

<img src = "https://2.bp.blogspot.com/-cqWoJCYQfr8/W-em6wJFewI/AAAAAAAAAFg/btxLMMvNvIsIEmvcdxFJ-UzX94vVbYy-gCLcBGAs/s1600/ATK.png" >

<h3> First technical task was to actually assemble the data that needs to put into a new warehouse. My choice of warehouse for this client was AWS Redshift. I built different scraper programs that gracefully and without putting a lot of load on web servers, gained all the data I needed. </h3>
  
<h3> Here is a snippet of the python program I used to gain data from Lens: </h3>
  
  <!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">query <span style="color: #333333">=</span> query.<span style="color: #008800; font-weight: bold">replace</span>(<span style="color: #AA6600">&quot;(&quot;</span>, <span style="color: #AA6600">&quot;%28&quot;</span>)

<span style="color: #008800; font-weight: bold">from</span> fullpath import path

<span style="color: #008800; font-weight: bold">class</span> S1(Spider):
    name <span style="color: #333333">=</span> <span style="background-color: #fff0f0">&#39;s1&#39;</span>
    start_urls <span style="color: #333333">=</span> [<span style="color: #AA6600">&quot;https://www.lens.org/lens/search?q=blockchain%20payments&amp;v=table&amp;p=0&amp;n=50&quot;</span>]
    custom_settings <span style="color: #333333">=</span> <span style="color: #FF0000; background-color: #FFAAAA">{</span> <span style="background-color: #fff0f0">&#39;DOWNLOAD_DELAY&#39;</span>: <span style="color: #0000DD; font-weight: bold">0</span>.<span style="color: #0000DD; font-weight: bold">5</span> <span style="color: #FF0000; background-color: #FFAAAA">}</span>
    def parse(<span style="color: #008800; font-weight: bold">self</span>, response):
        <span style="color: #008800; font-weight: bold">names</span> <span style="color: #333333">=</span> response.xpath(<span style="background-color: #fff0f0">&#39;//header&#39;</span>)
        ans<span style="color: #333333">=</span>[]
        <span style="color: #008800; font-weight: bold">for</span> name <span style="color: #008800; font-weight: bold">in</span> <span style="color: #008800; font-weight: bold">names</span>[<span style="color: #0000DD; font-weight: bold">2</span>:<span style="color: #0000DD; font-weight: bold">27</span>]:
            item <span style="color: #333333">=</span> <span style="color: #FF0000; background-color: #FFAAAA">{}</span>
            item[<span style="background-color: #fff0f0">&#39;Title&#39;</span>] <span style="color: #333333">=</span> name.xpath(<span style="color: #AA6600">&quot;./div[@class=&#39;listing-header clearfix&#39;]/div[@class=&#39;listing-with-sidebar&#39;]/h3/a/text()&quot;</span>).<span style="color: #008800; font-weight: bold">extract</span>()[<span style="color: #0000DD; font-weight: bold">0</span>]
            item[<span style="background-color: #fff0f0">&#39;url&#39;</span>] <span style="color: #333333">=</span> name.xpath(<span style="color: #AA6600">&quot;./div[@class=&#39;listing-header clearfix&#39;]/div[@class=&#39;listing-with-sidebar&#39;]/h3/a/@href&quot;</span>).<span style="color: #008800; font-weight: bold">extract</span>()[<span style="color: #0000DD; font-weight: bold">0</span>]
</pre></div>

  <h3> Here is a snippet of the python program I used to pull data from USPTO and Pair. </h3>
  
  <!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">def parse_2(<span style="color: #008800; font-weight: bold">self</span>, response):
        <span style="color: #333333">#</span> <span style="color: #008800; font-weight: bold">structure</span> <span style="color: #008800; font-weight: bold">of</span> the files handled <span style="color: #008800; font-weight: bold">by</span> parse_2
        <span style="color: #333333">#</span> <span style="color: #333333">/</span>html<span style="color: #333333">/</span>body<span style="color: #333333">/</span>ul<span style="color: #333333">/</span>li[<span style="color: #333333">@</span><span style="color: #008800; font-weight: bold">class</span><span style="color: #333333">=</span><span style="color: #AA6600">&quot;first&quot;</span>]
        it <span style="color: #333333">=</span> response.meta[<span style="background-color: #fff0f0">&#39;foo&#39;</span>]
        <span style="color: #008800; font-weight: bold">first</span> <span style="color: #333333">=</span> response.xpath(<span style="background-color: #fff0f0">&#39;//p[1]/text()&#39;</span>).<span style="color: #008800; font-weight: bold">extract</span>()
        <span style="color: #008800; font-weight: bold">second</span> <span style="color: #333333">=</span> response.xpath(<span style="background-color: #fff0f0">&#39;//tr[3]/td/b/text()&#39;</span>)[<span style="color: #0000DD; font-weight: bold">0</span>].<span style="color: #008800; font-weight: bold">extract</span>()
        third <span style="color: #333333">=</span> response.xpath(<span style="background-color: #fff0f0">&#39;//coma/text()&#39;</span>).<span style="color: #008800; font-weight: bold">extract</span>()
        fourth <span style="color: #333333">=</span> response.xpath(<span style="background-color: #fff0f0">&#39;//tr[2]/td[2]&#39;</span>).<span style="color: #008800; font-weight: bold">extract</span>()
        it[<span style="background-color: #fff0f0">&#39;Abstract&#39;</span>] <span style="color: #333333">=</span> <span style="color: #008800; font-weight: bold">first</span>
        it[<span style="background-color: #fff0f0">&#39;Company&#39;</span>] <span style="color: #333333">=</span> <span style="color: #008800; font-weight: bold">second</span>
        <span style="color: #008800; font-weight: bold">for</span> x <span style="color: #008800; font-weight: bold">in</span> fourth:
            if len(x) <span style="color: #333333">&gt;</span> <span style="color: #0000DD; font-weight: bold">40</span>:
                pull <span style="color: #333333">=</span> x[<span style="color: #0000DD; font-weight: bold">43</span>:len(x)<span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">5</span>]
        pull <span style="color: #333333">=</span> pull.<span style="color: #008800; font-weight: bold">replace</span>(<span style="color: #AA6600">&quot;&amp;amp;nbsp&quot;</span>,<span style="color: #AA6600">&quot;&quot;</span>)
</pre></div>

  <h3> Upon getting this data in the form of textfiles, I had to aggregate them to a single storage area and I chose AWS S3 as it is easier to import this data to a data warehouse such as Redshift. </h3>
  
  <h3> The text files looked like below when I opened them in Excel for ease. There are about 200000+ rows when all the files are combined and ther are about 15+ columns for each row. </h3>
  
  <img src="https://3.bp.blogspot.com/-L81mUYUmnVs/W-epe_UkOPI/AAAAAAAAAF4/TZqMEICyUEo6C9KAZ03V0kP7QCLz3VxpQCLcBGAs/s1600/ATK.png">
  
  <h3> I set up a Redshift cluster with 4 nodes in a Multi-node architecture set up. Here, one of my nodes was the Leader node which was to perform the planning of query execution, code compilation and code distribution to the specific compute nodes which have the data. I chose to use the dc2.large instances as I was planning to have less than 500GB of data so I felt the dense storage node option might become overkill for this operation. I created a database called as "patents" which will hold all the patent information. </h3>
  
  <h3> Surprisingly, AWS does not provide a query editor for download, hence I decided to use the Aginity workbench. I downloaded the workbench and connected to the new database that I have created over the 5439 port. I had to create new entries in my existing security group to ensure that this connection was allowed. </h3>
  
  <h3> There were several issues while loading data from S3 to Redshift mainly because some of the data was not formatted properly and hence was not satisfying the constraints of the table that I had created. This involved cleaning up some dirty characters and removing "," from several of the strings so that it does not affect the delimiter. I was looking into the pg_catalog and the table for load errors to find why my data was misbehaving. </h3>
  
  <!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">SELECT</span> <span style="color: #333333">*</span> <span style="color: #008800; font-weight: bold">from</span> pg_catalog<span style="color: #6600EE; font-weight: bold">.</span>stl_load_errors;
</pre></div>

  <h3> After fixing and cleaning the data, I was able to load the data onto the newly created tables in RedShift using the following: </h3>
  
  <!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">copy</span> patents <span style="color: #008800; font-weight: bold">from</span> <span style="background-color: #fff0f0">&#39;s3://redshiftstuff/stuff.txt&#39;</span> 
credentials <span style="background-color: #fff0f0">&#39;aws_iam_role=arn:aws:iam::XXXXXXXX:role/RedShiftS3&#39;</span>
<span style="color: #008800; font-weight: bold">delimiter</span> <span style="background-color: #fff0f0">&#39;,&#39;</span>;
</pre></div>

  <h3> Post this, the database was ready to be used for analytical querying by the client to get insights about the patent filing and patent analytics in the field of their interest. Prior to this solution, there was no existing solution of bringing together the different patent databases and creation of a single analytical point. Sample analytical queries that were run using Postgres on the Aginity workbench were : </h3>
  
  <!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">SELECT</span> <span style="color: #333333">*</span> <span style="color: #008800; font-weight: bold">FROM</span> patents
<span style="color: #008800; font-weight: bold">WHERE</span> applicants <span style="color: #333333">=</span> <span style="background-color: #fff0f0">&#39;BANK OF AMERICA&#39;</span>
<span style="color: #008800; font-weight: bold">AND</span> cited_count <span style="color: #333333">&gt;</span> <span style="color: #6600EE; font-weight: bold">2</span>
<span style="color: #008800; font-weight: bold">AND</span> classification <span style="color: #008800; font-weight: bold">like</span> <span style="background-color: #fff0f0">&#39;%G06%&#39;</span>;
</pre></div>
  
  <!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">SELECT</span> applicants, count(Title),<span style="color: #008800; font-weight: bold">RIGHT</span>(publication_date,<span style="color: #6600EE; font-weight: bold">4</span>) <span style="color: #008800; font-weight: bold">AS</span> <span style="background-color: #fff0f0">&quot;Year1&quot;</span>
<span style="color: #008800; font-weight: bold">FROM</span> patents
<span style="color: #008800; font-weight: bold">GROUP</span> <span style="color: #008800; font-weight: bold">BY</span> applicants,Year1
<span style="color: #008800; font-weight: bold">ORDER</span> <span style="color: #008800; font-weight: bold">BY</span> applicants,Year1
</pre></div>


  <h3> I also provided documentation to the client as to how they can add data, remove data and how they can look to expand the solution which is based on AWS. </h3>
  
  
  

